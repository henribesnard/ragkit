# RAGKIT V1 ‚Äî Plan d'Impl√©mentation

## üìã Informations du Document

| Champ | Valeur |
|-------|--------|
| **Version** | 1.0 |
| **Derni√®re mise √† jour** | 30/01/2026 |
| **Auteur** | Codex |
| **Statut global** | üü° En cours |

### L√©gende des Statuts

- üî¥ Non d√©marr√©
- üü° En cours
- üü¢ Termin√©
- ‚è∏Ô∏è Bloqu√©
- üîµ En revue

---

## üìö Documents de R√©f√©rence

Avant de commencer l'impl√©mentation, lire attentivement :

1. **[CONTEXT.md](./CONTEXT.md)** - Contexte complet du projet, architecture, conventions
2. **[ragkit-v1-config.yaml](./ragkit-v1-config.yaml)** - Configuration de r√©f√©rence V1
3. Ce document (IMPLEMENTATION_PLAN.md)

---

## üéØ Objectifs V1

### P√©rim√®tre Fonctionnel

| Feature | Inclus V1 | Notes |
|---------|-----------|-------|
| Config YAML + validation | ‚úÖ | Pydantic V2 |
| Ingestion locale (PDF, DOCX, MD, TXT) | ‚úÖ | unstructured/docling |
| Chunking (fixed, semantic) | ‚úÖ | |
| Embedding (OpenAI, Ollama, Cohere) | ‚úÖ | |
| Vector Store (Qdrant, ChromaDB) | ‚úÖ | |
| Retrieval (semantic, lexical, hybrid) | ‚úÖ | |
| Reranking (Cohere) | ‚úÖ | |
| LLM (OpenAI, Anthropic, Ollama) | ‚úÖ | via LiteLLM |
| Agents par d√©faut | ‚úÖ | query_analyzer + response_generator |
| Chatbot Gradio | ‚úÖ | |
| API REST basique | ‚úÖ | FastAPI |
| CLI (init, ingest, serve, query) | ‚úÖ | Typer |
| Multi-agent custom | ‚ùå | V2 |
| Sources cloud (S3, Notion, etc.) | ‚ùå | V2 |
| √âvaluation automatique | ‚ùå | V2 |
| Authentication | ‚ùå | V2 |

### Crit√®res de Succ√®s V1

- [ ] Un utilisateur peut d√©ployer un RAG fonctionnel en < 10 minutes
- [ ] Configuration 100% YAML (aucun code requis)
- [ ] Pipeline complet : ingest ‚Üí query ‚Üí response
- [ ] Chatbot web accessible
- [ ] API document√©e et fonctionnelle
- [ ] Tests unitaires > 80% coverage sur modules critiques

---

## üèóÔ∏è Plan d'Impl√©mentation

### Vue d'Ensemble des Phases

```
Phase 1: Foundation (Semaine 1)
    ‚îî‚îÄ‚îÄ Setup projet, Config, Mod√®les de donn√©es

Phase 2: Ingestion Pipeline (Semaine 2)
    ‚îî‚îÄ‚îÄ Sources, Parsers, Chunkers

Phase 3: Embedding & Storage (Semaine 3)  
    ‚îî‚îÄ‚îÄ Embedders, Vector Stores

Phase 4: Retrieval Engine (Semaine 4)
    ‚îî‚îÄ‚îÄ Semantic, Lexical, Fusion, Rerank

Phase 5: LLM & Agents (Semaine 5)
    ‚îî‚îÄ‚îÄ LLM Provider, Query Analyzer, Response Generator

Phase 6: Interfaces (Semaine 6)
    ‚îî‚îÄ‚îÄ CLI, API REST, Chatbot Gradio

Phase 7: Integration & Polish (Semaine 7)
    ‚îî‚îÄ‚îÄ Tests E2E, Documentation, Packaging
```

---

## Phase 1 : Foundation

**Dur√©e estim√©e** : 5 jours  
**Statut** : üü¢ Termin√©

### 1.1 Setup du Projet

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **1.1.1** Cr√©er le repository Git
  - [x] Initialiser avec `.gitignore` Python
  - [x] Ajouter `LICENSE` (Apache 2.0)
  - [x] Cr√©er `README.md` initial

- [x] **1.1.2** Configurer `pyproject.toml`
  ```toml
  [project]
  name = "ragkit"
  version = "1.0.0"
  description = "Configuration-First Agentic RAG Framework"
  requires-python = ">=3.10"
  
  dependencies = [
      "pydantic>=2.0",
      "pydantic-settings>=2.0",
      "pyyaml>=6.0",
      "litellm>=1.0",
      "fastapi>=0.100",
      "uvicorn>=0.20",
      "gradio>=4.0",
      "typer>=0.9",
      "structlog>=23.0",
      "qdrant-client>=1.6",
      "chromadb>=0.4",
      "unstructured>=0.10",
      "rank-bm25>=0.2",
  ]
  
  [project.optional-dependencies]
  dev = [
      "pytest>=7.0",
      "pytest-asyncio>=0.21",
      "pytest-cov>=4.0",
      "ruff>=0.1",
      "mypy>=1.0",
  ]
  ```

- [x] **1.1.3** Configurer les outils de d√©veloppement
  - [x] `ruff.toml` pour linting/formatting
  - [x] `mypy.ini` pour type checking
  - [x] `pytest.ini` pour tests
  - [x] `.pre-commit-config.yaml`

- [x] **1.1.4** Cr√©er la structure de r√©pertoires
  ```
  ragkit/
  ‚îú‚îÄ‚îÄ ragkit/
  ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
  ‚îÇ   ‚îú‚îÄ‚îÄ config/
  ‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
  ‚îÇ   ‚îú‚îÄ‚îÄ embedding/
  ‚îÇ   ‚îú‚îÄ‚îÄ vectorstore/
  ‚îÇ   ‚îú‚îÄ‚îÄ retrieval/
  ‚îÇ   ‚îú‚îÄ‚îÄ llm/
  ‚îÇ   ‚îú‚îÄ‚îÄ agents/
  ‚îÇ   ‚îú‚îÄ‚îÄ chatbot/
  ‚îÇ   ‚îú‚îÄ‚îÄ api/
  ‚îÇ   ‚îú‚îÄ‚îÄ cli/
  ‚îÇ   ‚îî‚îÄ‚îÄ utils/
  ‚îú‚îÄ‚îÄ tests/
  ‚îú‚îÄ‚îÄ templates/
  ‚îî‚îÄ‚îÄ examples/
  ```

#### Test de Validation 1.1

```bash
# Le projet doit √™tre installable
pip install -e ".[dev]"

# Les imports doivent fonctionner
python -c "import ragkit; print(ragkit.__version__)"
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires ex√©cut√©s via `pytest` (7 tests OK). Avertissement pytest-asyncio sur `asyncio_default_fixture_loop_scope` (√† pr√©ciser plus tard).

---

### 1.2 Syst√®me de Configuration

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **1.2.1** Cr√©er les mod√®les Pydantic de base (`ragkit/config/schema.py`)
  
  ```python
  # Mod√®les √† impl√©menter :
  class ProjectConfig(BaseModel): ...
  class IngestionConfig(BaseModel): ...
  class EmbeddingConfig(BaseModel): ...
  class VectorStoreConfig(BaseModel): ...
  class RetrievalConfig(BaseModel): ...
  class LLMConfig(BaseModel): ...
  class AgentsConfig(BaseModel): ...
  class ChatbotConfig(BaseModel): ...
  class APIConfig(BaseModel): ...
  class ObservabilityConfig(BaseModel): ...
  
  class RAGKitConfig(BaseModel):
      """Configuration racine"""
      version: str
      project: ProjectConfig
      ingestion: IngestionConfig
      embedding: EmbeddingConfig
      vector_store: VectorStoreConfig
      retrieval: RetrievalConfig
      llm: LLMConfig
      agents: AgentsConfig
      chatbot: ChatbotConfig
      api: APIConfig
      observability: ObservabilityConfig
  ```

- [x] **1.2.2** Impl√©menter le ConfigLoader (`ragkit/config/loader.py`)
  
  ```python
  class ConfigLoader:
      """Charge et valide la configuration YAML"""
      
      def load(self, path: Path) -> RAGKitConfig:
          """Charge un fichier YAML et retourne la config valid√©e"""
          
      def load_with_env(self, path: Path) -> RAGKitConfig:
          """Charge et r√©sout les variables d'environnement (*_env)"""
          
      def validate(self, config: RAGKitConfig) -> list[str]:
          """Valide la coh√©rence de la configuration"""
  ```

- [x] **1.2.3** Impl√©menter la r√©solution des variables d'environnement
  - Pattern : `api_key_env: "OPENAI_API_KEY"` ‚Üí r√©sout vers `os.environ["OPENAI_API_KEY"]`
  - Gestion des erreurs si variable manquante

- [x] **1.2.4** Impl√©menter les validateurs custom (`ragkit/config/validators.py`)
  - Validation des chemins de fichiers
  - Validation des URLs
  - Validation de la coh√©rence (ex: si `rerank.enabled`, alors `rerank.provider` requis)

- [x] **1.2.5** Cr√©er les templates de configuration
  - `templates/minimal.yaml` - Configuration minimale fonctionnelle
  - `templates/hybrid.yaml` - Avec recherche hybride
  - `templates/full.yaml` - Toutes les options

#### Test de Validation 1.2

```python
# tests/unit/test_config.py

def test_load_minimal_config():
    """Doit charger la config minimale sans erreur"""
    loader = ConfigLoader()
    config = loader.load(Path("templates/minimal.yaml"))
    assert config.version == "1.0"
    assert config.project.name is not None

def test_load_with_env_resolution():
    """Doit r√©soudre les variables d'environnement"""
    os.environ["TEST_API_KEY"] = "sk-test123"
    loader = ConfigLoader()
    config = loader.load_with_env(Path("tests/fixtures/config_with_env.yaml"))
    assert config.llm.primary.api_key == "sk-test123"

def test_validation_errors():
    """Doit d√©tecter les configurations invalides"""
    loader = ConfigLoader()
    with pytest.raises(ValidationError):
        loader.load(Path("tests/fixtures/invalid_config.yaml"))

def test_full_config_schema():
    """Doit valider la config compl√®te de r√©f√©rence"""
    loader = ConfigLoader()
    config = loader.load(Path("ragkit-v1-config.yaml"))
    # Toutes les sections doivent √™tre pr√©sentes
    assert config.ingestion is not None
    assert config.embedding is not None
    assert config.vector_store is not None
    assert config.retrieval is not None
    assert config.llm is not None
    assert config.agents is not None
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires ex√©cut√©s via `pytest` (7 tests OK). Avertissement pytest-asyncio sur `asyncio_default_fixture_loop_scope`.

---

### 1.3 Utilitaires de Base

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **1.3.1** Configurer le logging (`ragkit/utils/logging.py`)
  ```python
  def setup_logging(config: ObservabilityConfig) -> structlog.BoundLogger:
      """Configure structlog selon la config"""
  ```

- [x] **1.3.2** Cr√©er les utilitaires async (`ragkit/utils/async_utils.py`)
  ```python
  async def run_with_timeout(coro, timeout: float): ...
  async def retry_async(coro, max_retries: int, delay: float): ...
  async def gather_with_concurrency(coros, max_concurrent: int): ...
  ```

- [x] **1.3.3** Cr√©er les exceptions custom (`ragkit/exceptions.py`)
  ```python
  class RAGKitError(Exception): ...
  class ConfigError(RAGKitError): ...
  class IngestionError(RAGKitError): ...
  class EmbeddingError(RAGKitError): ...
  class RetrievalError(RAGKitError): ...
  class LLMError(RAGKitError): ...
  class AgentError(RAGKitError): ...
  ```

- [x] **1.3.4** Cr√©er les mod√®les de donn√©es partag√©s (`ragkit/models.py`)
  ```python
  class Document(BaseModel):
      id: str
      content: str
      metadata: dict[str, Any]
      embedding: list[float] | None = None
  
  class Chunk(BaseModel):
      id: str
      document_id: str
      content: str
      metadata: dict[str, Any]
      embedding: list[float] | None = None
      
  class RetrievalResult(BaseModel):
      chunk: Chunk
      score: float
      retrieval_type: str  # semantic | lexical | rerank
      
  class QueryAnalysis(BaseModel):
      intent: str
      needs_retrieval: bool
      rewritten_query: str | None
      reasoning: str
      
  class GeneratedResponse(BaseModel):
      content: str
      sources: list[str]
      metadata: dict[str, Any]
  ```

#### Test de Validation 1.3

```python
def test_logging_setup():
    """Le logging doit √™tre configur√© correctement"""
    from ragkit.utils.logging import setup_logging
    logger = setup_logging(ObservabilityConfig(logging=LoggingConfig(level="DEBUG")))
    assert logger is not None

def test_retry_async():
    """Le retry doit fonctionner"""
    call_count = 0
    
    async def failing_func():
        nonlocal call_count
        call_count += 1
        if call_count < 3:
            raise Exception("Temporary error")
        return "success"
    
    result = asyncio.run(retry_async(failing_func, max_retries=3, delay=0.1))
    assert result == "success"
    assert call_count == 3

def test_document_model():
    """Les mod√®les de donn√©es doivent √™tre valides"""
    doc = Document(
        id="doc1",
        content="Test content",
        metadata={"source": "test.pdf"}
    )
    assert doc.id == "doc1"
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires ex√©cut√©s via `pytest` (7 tests OK). Avertissement pytest-asyncio sur `asyncio_default_fixture_loop_scope`.

---

## Phase 2 : Ingestion Pipeline

**Dur√©e estim√©e** : 5 jours  
**Statut** : üü¢ Termin√©

### 2.1 Source Loaders

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **2.1.1** Cr√©er l'interface de base (`ragkit/ingestion/sources/base.py`)
  ```python
  class BaseSourceLoader(ABC):
      @abstractmethod
      async def load(self) -> AsyncIterator[RawDocument]:
          """Charge les documents depuis la source"""
          
      @abstractmethod
      def supports(self, source_config: SourceConfig) -> bool:
          """Indique si ce loader supporte la config donn√©e"""
  
  class RawDocument(BaseModel):
      content: bytes | str
      source_path: str
      file_type: str
      metadata: dict[str, Any]
  ```

- [x] **2.1.2** Impl√©menter le LocalSourceLoader (`ragkit/ingestion/sources/local.py`)
  ```python
  class LocalSourceLoader(BaseSourceLoader):
      """Charge les fichiers depuis le syst√®me de fichiers local"""
      
      def __init__(self, config: LocalSourceConfig):
          self.path = Path(config.path)
          self.patterns = config.patterns
          self.recursive = config.recursive
      
      async def load(self) -> AsyncIterator[RawDocument]:
          # Parcourir les fichiers matchant les patterns
          # Yield RawDocument pour chaque fichier
  ```

- [x] **2.1.3** Cr√©er la factory de loaders (`ragkit/ingestion/sources/__init__.py`)
  ```python
  def create_source_loader(config: SourceConfig) -> BaseSourceLoader:
      match config.type:
          case "local":
              return LocalSourceLoader(config)
          case _:
              raise ValueError(f"Unknown source type: {config.type}")
  ```

#### Test de Validation 2.1

```python
# tests/unit/test_sources.py

@pytest.fixture
def sample_files(tmp_path):
    """Cr√©e des fichiers de test"""
    (tmp_path / "doc1.pdf").write_bytes(b"PDF content")
    (tmp_path / "doc2.md").write_text("# Markdown")
    (tmp_path / "subdir").mkdir()
    (tmp_path / "subdir" / "doc3.txt").write_text("Text content")
    return tmp_path

async def test_local_loader_finds_files(sample_files):
    """Doit trouver tous les fichiers correspondant aux patterns"""
    config = LocalSourceConfig(
        type="local",
        path=str(sample_files),
        patterns=["*.pdf", "*.md", "*.txt"],
        recursive=True
    )
    loader = LocalSourceLoader(config)
    
    docs = [doc async for doc in loader.load()]
    assert len(docs) == 3

async def test_local_loader_respects_patterns(sample_files):
    """Doit filtrer selon les patterns"""
    config = LocalSourceConfig(
        type="local",
        path=str(sample_files),
        patterns=["*.pdf"],
        recursive=True
    )
    loader = LocalSourceLoader(config)
    
    docs = [doc async for doc in loader.load()]
    assert len(docs) == 1
    assert docs[0].file_type == "pdf"
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires ex√©cut√©s (sources/parsers/chunkers) : 7 tests OK. Avertissement pytest-asyncio sur `asyncio_default_fixture_loop_scope`.

---

### 2.2 Document Parsers

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **2.2.1** Cr√©er l'interface de base (`ragkit/ingestion/parsers/base.py`)
  ```python
  class BaseParser(ABC):
      @abstractmethod
      async def parse(self, raw_doc: RawDocument) -> ParsedDocument:
          """Parse un document brut en texte structur√©"""
      
      @abstractmethod
      def supports(self, file_type: str) -> bool:
          """Indique si ce parser supporte le type de fichier"""
  
  class ParsedDocument(BaseModel):
      content: str  # Texte extrait
      metadata: dict[str, Any]  # M√©tadonn√©es extraites
      structure: list[DocumentSection] | None  # Structure optionnelle
  ```

- [x] **2.2.2** Impl√©menter le PDFParser (`ragkit/ingestion/parsers/pdf.py`)
  - Utiliser `unstructured` comme backend par d√©faut
  - Option OCR si configur√©
  - Extraction des m√©tadonn√©es (titre, auteur, date)

- [x] **2.2.3** Impl√©menter le DOCXParser (`ragkit/ingestion/parsers/docx.py`)
  - Utiliser `unstructured` ou `python-docx`
  - Pr√©server la structure (titres, paragraphes)

- [x] **2.2.4** Impl√©menter le MarkdownParser (`ragkit/ingestion/parsers/markdown.py`)
  - Parser natif (pas de d√©pendance externe)
  - Pr√©server la structure des headings

- [x] **2.2.5** Impl√©menter le TextParser (`ragkit/ingestion/parsers/text.py`)
  - Parser simple pour fichiers .txt
  - D√©tection d'encodage

- [x] **2.2.6** Cr√©er la factory de parsers avec fallback (`ragkit/ingestion/parsers/__init__.py`)
  ```python
  def create_parser(config: ParsingConfig) -> BaseParser:
      """Cr√©e un parser composite qui route selon le file_type"""
  ```

#### Test de Validation 2.2

```python
# tests/unit/test_parsers.py

async def test_pdf_parser():
    """Doit extraire le texte d'un PDF"""
    raw_doc = RawDocument(
        content=Path("tests/fixtures/sample.pdf").read_bytes(),
        source_path="sample.pdf",
        file_type="pdf",
        metadata={}
    )
    parser = PDFParser(ParsingConfig())
    result = await parser.parse(raw_doc)
    
    assert len(result.content) > 0
    assert "title" in result.metadata or result.metadata.get("title") is None

async def test_markdown_parser_preserves_structure():
    """Doit pr√©server la structure du markdown"""
    content = """
# Title
## Section 1
Content of section 1.
## Section 2
Content of section 2.
"""
    raw_doc = RawDocument(
        content=content,
        source_path="doc.md",
        file_type="md",
        metadata={}
    )
    parser = MarkdownParser(ParsingConfig())
    result = await parser.parse(raw_doc)
    
    assert "Title" in result.content
    assert result.structure is not None
    assert len(result.structure) >= 2  # Au moins 2 sections
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires ex√©cut√©s (sources/parsers/chunkers) : 7 tests OK. Avertissement pytest-asyncio sur `asyncio_default_fixture_loop_scope`.

---

### 2.3 Chunking Strategies

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **2.3.1** Cr√©er l'interface de base (`ragkit/ingestion/chunkers/base.py`)
  ```python
  class BaseChunker(ABC):
      @abstractmethod
      def chunk(self, document: ParsedDocument) -> list[Chunk]:
          """D√©coupe un document en chunks"""
  ```

- [x] **2.3.2** Impl√©menter le FixedChunker (`ragkit/ingestion/chunkers/fixed.py`)
  ```python
  class FixedChunker(BaseChunker):
      """Chunking √† taille fixe avec overlap"""
      
      def __init__(self, chunk_size: int, chunk_overlap: int):
          self.chunk_size = chunk_size
          self.chunk_overlap = chunk_overlap
      
      def chunk(self, document: ParsedDocument) -> list[Chunk]:
          # Impl√©menter le d√©coupage par tokens
          # Utiliser tiktoken pour le comptage
  ```

- [x] **2.3.3** Impl√©menter le SemanticChunker (`ragkit/ingestion/chunkers/semantic.py`)
  ```python
  class SemanticChunker(BaseChunker):
      """Chunking bas√© sur la similarit√© s√©mantique"""
      
      def __init__(self, config: SemanticChunkingConfig, embedder: BaseEmbedder):
          self.similarity_threshold = config.similarity_threshold
          self.min_size = config.min_chunk_size
          self.max_size = config.max_chunk_size
          self.embedder = embedder
      
      def chunk(self, document: ParsedDocument) -> list[Chunk]:
          # 1. D√©couper en phrases
          # 2. Calculer les embeddings
          # 3. Grouper par similarit√©
  ```

- [x] **2.3.4** Cr√©er la factory de chunkers

#### Test de Validation 2.3

```python
# tests/unit/test_chunkers.py

def test_fixed_chunker_size():
    """Les chunks doivent respecter la taille configur√©e"""
    chunker = FixedChunker(chunk_size=100, chunk_overlap=20)
    doc = ParsedDocument(
        content="Lorem ipsum " * 100,  # Long document
        metadata={}
    )
    
    chunks = chunker.chunk(doc)
    
    assert len(chunks) > 1
    # Chaque chunk (sauf le dernier) doit avoir ~100 tokens
    for chunk in chunks[:-1]:
        token_count = count_tokens(chunk.content)
        assert 80 <= token_count <= 120  # Tol√©rance

def test_fixed_chunker_overlap():
    """Les chunks doivent avoir un chevauchement"""
    chunker = FixedChunker(chunk_size=50, chunk_overlap=10)
    doc = ParsedDocument(content="word " * 100, metadata={})
    
    chunks = chunker.chunk(doc)
    
    # V√©rifier que le d√©but du chunk N+1 contient la fin du chunk N
    for i in range(len(chunks) - 1):
        end_of_current = chunks[i].content[-50:]
        start_of_next = chunks[i+1].content[:50]
        # Il doit y avoir un overlap
        assert any(word in start_of_next for word in end_of_current.split()[-3:])

def test_semantic_chunker_groups_similar():
    """Le chunker s√©mantique doit grouper les phrases similaires"""
    # Test avec mock embedder
    ...
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires ex√©cut√©s (sources/parsers/chunkers) : 7 tests OK. Avertissement pytest-asyncio sur `asyncio_default_fixture_loop_scope`.

---

### 2.4 Ingestion Pipeline Orchestration

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **2.4.1** Cr√©er le pipeline orchestrator (`ragkit/ingestion/pipeline.py`)
  ```python
  class IngestionPipeline:
      """Orchestre le pipeline complet d'ingestion"""
      
      def __init__(self, config: IngestionConfig):
          self.source_loader = create_source_loader(config.sources[0])
          self.parser = create_parser(config.parsing)
          self.chunker = create_chunker(config.chunking)
      
      async def ingest(self) -> IngestionResult:
          """Ex√©cute le pipeline complet"""
          documents = []
          chunks = []
          
          async for raw_doc in self.source_loader.load():
              parsed = await self.parser.parse(raw_doc)
              doc_chunks = self.chunker.chunk(parsed)
              chunks.extend(doc_chunks)
              documents.append(parsed)
          
          return IngestionResult(
              documents_count=len(documents),
              chunks_count=len(chunks),
              chunks=chunks
          )
  ```

- [x] **2.4.2** Ajouter la gestion des erreurs et retry
- [x] **2.4.3** Ajouter le logging et les m√©triques
- [x] **2.4.4** Ajouter le mode incr√©mental (d√©tecter les fichiers modifi√©s)

#### Test de Validation 2.4

```python
# tests/integration/test_ingestion_pipeline.py

async def test_full_ingestion_pipeline(sample_documents_dir):
    """Le pipeline complet doit fonctionner"""
    config = IngestionConfig(
        sources=[LocalSourceConfig(path=str(sample_documents_dir), patterns=["*.md"])],
        parsing=ParsingConfig(engine="auto"),
        chunking=ChunkingConfig(strategy="fixed", fixed=FixedChunkingConfig(chunk_size=200))
    )
    
    pipeline = IngestionPipeline(config)
    result = await pipeline.ingest()
    
    assert result.documents_count > 0
    assert result.chunks_count > result.documents_count  # Plus de chunks que de docs
    assert all(chunk.content for chunk in result.chunks)  # Pas de chunks vides
```

**R√©sultat** : ‚¨ú Pass / ‚¨ú Fail  
**Notes** : Tests non √©crits pour le pipeline complet

---

## Phase 3 : Embedding & Storage

**Dur√©e estim√©e** : 4 jours  
**Statut** : üü¢ Termin√©

### 3.1 Embedding Providers

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **3.1.1** Cr√©er l'interface de base (`ragkit/embedding/base.py`)
  ```python
  class BaseEmbedder(ABC):
      @abstractmethod
      async def embed(self, texts: list[str]) -> list[list[float]]:
          """G√©n√®re les embeddings pour une liste de textes"""
      
      @abstractmethod
      async def embed_query(self, query: str) -> list[float]:
          """G√©n√®re l'embedding pour une requ√™te (peut avoir un prefix diff√©rent)"""
      
      @property
      @abstractmethod
      def dimensions(self) -> int:
          """Retourne la dimension des embeddings"""
  ```

- [x] **3.1.2** Impl√©menter OpenAIEmbedder (`ragkit/embedding/providers/openai.py`)
  ```python
  class OpenAIEmbedder(BaseEmbedder):
      def __init__(self, config: OpenAIEmbeddingConfig):
          self.client = AsyncOpenAI(api_key=config.api_key)
          self.model = config.model
          self._dimensions = config.dimensions
      
      async def embed(self, texts: list[str]) -> list[list[float]]:
          # Batching automatique
          # Retry avec backoff
  ```

- [x] **3.1.3** Impl√©menter OllamaEmbedder (`ragkit/embedding/providers/ollama.py`)
- [x] **3.1.4** Impl√©menter CohereEmbedder (`ragkit/embedding/providers/cohere.py`)
- [x] **3.1.5** Impl√©menter le cache d'embeddings (`ragkit/embedding/cache.py`)
  ```python
  class EmbeddingCache:
      """Cache pour √©viter de recalculer les embeddings"""
      
      def __init__(self, backend: str, ttl: int):
          ...
      
      async def get(self, text_hash: str) -> list[float] | None: ...
      async def set(self, text_hash: str, embedding: list[float]): ...
  ```

- [x] **3.1.6** Cr√©er la factory d'embedders

#### Test de Validation 3.1

```python
# tests/unit/test_embedding.py

@pytest.mark.asyncio
async def test_openai_embedder(mock_openai):
    """L'embedder OpenAI doit retourner des embeddings valides"""
    config = OpenAIEmbeddingConfig(
        provider="openai",
        model="text-embedding-3-small",
        api_key="test-key"
    )
    embedder = OpenAIEmbedder(config)
    
    embeddings = await embedder.embed(["Hello world", "Test text"])
    
    assert len(embeddings) == 2
    assert len(embeddings[0]) == embedder.dimensions
    assert all(isinstance(x, float) for x in embeddings[0])

@pytest.mark.asyncio
async def test_embedding_cache():
    """Le cache doit √©viter les appels redondants"""
    cache = EmbeddingCache(backend="memory", ttl=3600)
    mock_embedder = MockEmbedder()
    cached_embedder = CachedEmbedder(mock_embedder, cache)
    
    # Premier appel
    await cached_embedder.embed(["text1"])
    assert mock_embedder.call_count == 1
    
    # Deuxi√®me appel (m√™me texte) - doit utiliser le cache
    await cached_embedder.embed(["text1"])
    assert mock_embedder.call_count == 1  # Pas d'appel suppl√©mentaire
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires ex√©cut√©s (cache) : OK

---

### 3.2 Vector Store Providers

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **3.2.1** Cr√©er l'interface de base (`ragkit/vectorstore/base.py`)
  ```python
  class BaseVectorStore(ABC):
      @abstractmethod
      async def add(self, chunks: list[Chunk]) -> None:
          """Ajoute des chunks au store"""
      
      @abstractmethod
      async def search(
          self, 
          query_embedding: list[float], 
          top_k: int,
          filters: dict | None = None
      ) -> list[SearchResult]:
          """Recherche par similarit√© vectorielle"""
      
      @abstractmethod
      async def delete(self, ids: list[str]) -> None:
          """Supprime des chunks par ID"""
      
      @abstractmethod
      async def clear(self) -> None:
          """Vide le store"""
  
  class SearchResult(BaseModel):
      chunk: Chunk
      score: float
  ```

- [x] **3.2.2** Impl√©menter QdrantVectorStore (`ragkit/vectorstore/providers/qdrant.py`)
  ```python
  class QdrantVectorStore(BaseVectorStore):
      def __init__(self, config: QdrantConfig):
          self.client = QdrantClient(
              location=":memory:" if config.mode == "memory" else config.url,
              api_key=config.api_key
          )
          self.collection_name = config.collection_name
          self._ensure_collection()
  ```

- [x] **3.2.3** Impl√©menter ChromaVectorStore (`ragkit/vectorstore/providers/chroma.py`)
- [x] **3.2.4** Cr√©er la factory de vector stores

#### Test de Validation 3.2

```python
# tests/integration/test_vectorstore.py

@pytest.fixture
async def qdrant_store():
    config = QdrantConfig(mode="memory", collection_name="test")
    store = QdrantVectorStore(config)
    yield store
    await store.clear()

@pytest.mark.asyncio
async def test_add_and_search(qdrant_store, sample_chunks_with_embeddings):
    """Doit pouvoir ajouter et rechercher des chunks"""
    await qdrant_store.add(sample_chunks_with_embeddings)
    
    query_embedding = sample_chunks_with_embeddings[0].embedding
    results = await qdrant_store.search(query_embedding, top_k=5)
    
    assert len(results) <= 5
    assert results[0].score > 0.9  # Le premier r√©sultat doit √™tre tr√®s similaire

@pytest.mark.asyncio
async def test_search_with_filters(qdrant_store):
    """Doit filtrer par m√©tadonn√©es"""
    chunks = [
        Chunk(id="1", content="Doc A", metadata={"category": "tech"}, embedding=[...]),
        Chunk(id="2", content="Doc B", metadata={"category": "finance"}, embedding=[...]),
    ]
    await qdrant_store.add(chunks)
    
    results = await qdrant_store.search(
        query_embedding=[...],
        top_k=10,
        filters={"category": "tech"}
    )
    
    assert all(r.chunk.metadata["category"] == "tech" for r in results)
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests d'int√©gration ex√©cut√©s (Qdrant/Chroma) : OK. Avertissements de d√©pr√©ciation c√¥t√© clients.

---

## Phase 4 : Retrieval Engine

**Dur√©e estim√©e** : 5 jours  
**Statut** : üü¢ Termin√©

### 4.1 Semantic Search

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **4.1.1** Impl√©menter la recherche s√©mantique (`ragkit/retrieval/semantic.py`)
  ```python
  class SemanticRetriever:
      def __init__(
          self, 
          vector_store: BaseVectorStore,
          embedder: BaseEmbedder,
          config: SemanticConfig
      ):
          self.vector_store = vector_store
          self.embedder = embedder
          self.top_k = config.top_k
          self.threshold = config.similarity_threshold
      
      async def retrieve(self, query: str) -> list[RetrievalResult]:
          query_embedding = await self.embedder.embed_query(query)
          results = await self.vector_store.search(query_embedding, self.top_k)
          
          # Filtrer par threshold
          filtered = [r for r in results if r.score >= self.threshold]
          
          return [
              RetrievalResult(
                  chunk=r.chunk,
                  score=r.score,
                  retrieval_type="semantic"
              )
              for r in filtered
          ]
  ```

#### Test de Validation 4.1

```python
@pytest.mark.asyncio
async def test_semantic_retrieval(populated_vector_store, embedder):
    """La recherche s√©mantique doit retourner des r√©sultats pertinents"""
    config = SemanticConfig(enabled=True, top_k=5, similarity_threshold=0.5)
    retriever = SemanticRetriever(populated_vector_store, embedder, config)
    
    results = await retriever.retrieve("What is machine learning?")
    
    assert len(results) > 0
    assert all(r.retrieval_type == "semantic" for r in results)
    # Les scores doivent √™tre tri√©s par ordre d√©croissant
    scores = [r.score for r in results]
    assert scores == sorted(scores, reverse=True)
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires ex√©cut√©s (semantic/engine) : OK

---

### 4.2 Lexical Search (BM25)

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **4.2.1** Impl√©menter l'index BM25 (`ragkit/retrieval/lexical.py`)
  ```python
  class LexicalRetriever:
      def __init__(self, config: LexicalConfig):
          self.bm25 = None  # Initialis√© lors de l'indexation
          self.chunks = []
          self.config = config
          self.preprocessor = TextPreprocessor(config.preprocessing)
      
      def index(self, chunks: list[Chunk]) -> None:
          """Construit l'index BM25"""
          self.chunks = chunks
          tokenized = [self.preprocessor.tokenize(c.content) for c in chunks]
          self.bm25 = BM25Okapi(tokenized, k1=self.config.params.k1, b=self.config.params.b)
      
      def retrieve(self, query: str) -> list[RetrievalResult]:
          tokenized_query = self.preprocessor.tokenize(query)
          scores = self.bm25.get_scores(tokenized_query)
          # Retourner les top_k
  ```

- [x] **4.2.2** Impl√©menter le TextPreprocessor
  - Lowercase
  - Stopwords removal (fran√ßais/anglais)
  - Stemming optionnel

#### Test de Validation 4.2

```python
def test_lexical_retrieval():
    """BM25 doit trouver les documents avec les mots-cl√©s"""
    config = LexicalConfig(
        enabled=True,
        top_k=5,
        preprocessing=PreprocessingConfig(lowercase=True, remove_stopwords=True)
    )
    retriever = LexicalRetriever(config)
    
    chunks = [
        Chunk(id="1", content="Python programming language tutorial"),
        Chunk(id="2", content="Java development best practices"),
        Chunk(id="3", content="Python machine learning guide"),
    ]
    retriever.index(chunks)
    
    results = retriever.retrieve("Python programming")
    
    assert len(results) > 0
    # Les chunks avec "Python" doivent √™tre en premier
    assert "Python" in results[0].chunk.content
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires ex√©cut√©s (lexical) : OK

---

### 4.3 Score Fusion

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **4.3.1** Impl√©menter les m√©thodes de fusion (`ragkit/retrieval/fusion.py`)
  ```python
  class ScoreFusion:
      @staticmethod
      def weighted_sum(
          results_by_type: dict[str, list[RetrievalResult]],
          weights: dict[str, float],
          normalize: bool = True
      ) -> list[RetrievalResult]:
          """Fusion par somme pond√©r√©e"""
      
      @staticmethod
      def reciprocal_rank_fusion(
          results_by_type: dict[str, list[RetrievalResult]],
          k: int = 60
      ) -> list[RetrievalResult]:
          """Fusion par RRF"""
          # RRF(d) = Œ£ 1/(k + rank(d))
  ```

#### Test de Validation 4.3

```python
def test_rrf_fusion():
    """RRF doit combiner les rankings de mani√®re √©quilibr√©e"""
    semantic_results = [
        RetrievalResult(chunk=Chunk(id="A"), score=0.9, retrieval_type="semantic"),
        RetrievalResult(chunk=Chunk(id="B"), score=0.8, retrieval_type="semantic"),
    ]
    lexical_results = [
        RetrievalResult(chunk=Chunk(id="B"), score=0.95, retrieval_type="lexical"),
        RetrievalResult(chunk=Chunk(id="C"), score=0.85, retrieval_type="lexical"),
    ]
    
    fused = ScoreFusion.reciprocal_rank_fusion(
        {"semantic": semantic_results, "lexical": lexical_results},
        k=60
    )
    
    # B appara√Æt dans les deux, devrait √™tre bien class√©
    ids = [r.chunk.id for r in fused]
    assert "B" in ids[:2]  # B dans le top 2
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires ex√©cut√©s (fusion) : OK

---

### 4.4 Reranking

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **4.4.1** Cr√©er l'interface de reranker (`ragkit/retrieval/rerank.py`)
  ```python
  class BaseReranker(ABC):
      @abstractmethod
      async def rerank(
          self, 
          query: str, 
          results: list[RetrievalResult],
          top_n: int
      ) -> list[RetrievalResult]:
          """Rerank les r√©sultats"""
  
  class CohereReranker(BaseReranker):
      def __init__(self, config: RerankConfig):
          self.client = cohere.AsyncClient(api_key=config.api_key)
          self.model = config.model
      
      async def rerank(self, query: str, results: list[RetrievalResult], top_n: int):
          documents = [r.chunk.content for r in results]
          response = await self.client.rerank(
              query=query,
              documents=documents,
              model=self.model,
              top_n=top_n
          )
          # Reconstruire les r√©sultats avec les nouveaux scores
  ```

#### Test de Validation 4.4

```python
@pytest.mark.asyncio
async def test_cohere_reranker(mock_cohere):
    """Le reranker doit r√©ordonner les r√©sultats"""
    config = RerankConfig(provider="cohere", model="rerank-v3.5", api_key="test")
    reranker = CohereReranker(config)
    
    results = [
        RetrievalResult(chunk=Chunk(id="1", content="Relevant doc"), score=0.5),
        RetrievalResult(chunk=Chunk(id="2", content="Very relevant doc"), score=0.6),
        RetrievalResult(chunk=Chunk(id="3", content="Irrelevant doc"), score=0.7),
    ]
    
    reranked = await reranker.rerank("relevant query", results, top_n=2)
    
    assert len(reranked) == 2
    # L'ordre peut avoir chang√© par rapport aux scores originaux
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Reranker NoOp/Cohere impl√©ment√©s (tests cohere non ex√©cut√©s).

---

### 4.5 Retrieval Engine (Orchestration)

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **4.5.1** Cr√©er le moteur de retrieval principal (`ragkit/retrieval/engine.py`)
  ```python
  class RetrievalEngine:
      """Orchestre tout le pipeline de retrieval"""
      
      def __init__(
          self,
          config: RetrievalConfig,
          vector_store: BaseVectorStore,
          embedder: BaseEmbedder
      ):
          self.config = config
          self.semantic = SemanticRetriever(...) if config.semantic.enabled else None
          self.lexical = LexicalRetriever(...) if config.lexical.enabled else None
          self.reranker = create_reranker(config.rerank) if config.rerank.enabled else None
          self.fusion = ScoreFusion()
      
      async def retrieve(self, query: str) -> list[RetrievalResult]:
          results_by_type = {}
          
          # 1. Recherche s√©mantique (si activ√©e)
          if self.semantic:
              results_by_type["semantic"] = await self.semantic.retrieve(query)
          
          # 2. Recherche lexicale (si activ√©e)
          if self.lexical:
              results_by_type["lexical"] = self.lexical.retrieve(query)
          
          # 3. Fusion des scores
          fused = self.fusion.apply(results_by_type, self.config.fusion)
          
          # 4. Reranking (si activ√©)
          if self.reranker:
              fused = await self.reranker.rerank(query, fused, self.config.rerank.top_n)
          
          # 5. Formatage du contexte
          return self._prepare_context(fused)
  ```

#### Test de Validation 4.5

```python
@pytest.mark.asyncio
async def test_full_retrieval_pipeline():
    """Le pipeline complet doit fonctionner"""
    config = RetrievalConfig(
        architecture="hybrid_rerank",
        semantic=SemanticConfig(enabled=True, weight=0.5, top_k=20),
        lexical=LexicalConfig(enabled=True, weight=0.5, top_k=20),
        rerank=RerankConfig(enabled=True, provider="cohere", top_n=5),
        fusion=FusionConfig(method="reciprocal_rank_fusion")
    )
    
    engine = RetrievalEngine(config, vector_store, embedder)
    results = await engine.retrieve("What is the capital of France?")
    
    assert len(results) <= 5  # Respecte top_n du reranker
    assert all(isinstance(r, RetrievalResult) for r in results)
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires ex√©cut√©s (engine) : OK

---

## Phase 5 : LLM & Agents

**Dur√©e estim√©e** : 5 jours  
**Statut** : üü¢ Termin√©

### 5.1 LLM Provider

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **5.1.1** Cr√©er le wrapper LiteLLM (`ragkit/llm/litellm_provider.py`)
  ```python
  class LLMProvider:
      """Wrapper unifi√© pour tous les LLM via LiteLLM"""
      
      def __init__(self, config: LLMProviderConfig):
          self.model = f"{config.provider}/{config.model}"
          self.params = config.params.model_dump()
          self.timeout = config.timeout
          self.max_retries = config.max_retries
      
      async def complete(self, messages: list[dict]) -> str:
          """Appel de compl√©tion simple"""
          response = await acompletion(
              model=self.model,
              messages=messages,
              **self.params
          )
          return response.choices[0].message.content
      
      async def complete_json(self, messages: list[dict], schema: dict) -> dict:
          """Compl√©tion avec output JSON structur√©"""
          # Ajouter instruction JSON au prompt
          # Parser et valider la r√©ponse
  ```

- [x] **5.1.2** Impl√©menter le routing de mod√®les
  ```python
  class LLMRouter:
      """Route vers le bon mod√®le selon la config"""
      
      def __init__(self, config: LLMConfig):
          self.primary = LLMProvider(config.primary)
          self.secondary = LLMProvider(config.secondary) if config.secondary else None
          self.fast = LLMProvider(config.fast) if config.fast else None
      
      def get(self, model_ref: str) -> LLMProvider:
          match model_ref:
              case "primary": return self.primary
              case "secondary": return self.secondary
              case "fast": return self.fast
  ```

#### Test de Validation 5.1

```python
@pytest.mark.asyncio
async def test_llm_completion(mock_litellm):
    """Le LLM doit retourner une r√©ponse"""
    config = LLMProviderConfig(
        provider="openai",
        model="gpt-4o-mini",
        api_key="test",
        params=LLMParams(temperature=0.7)
    )
    llm = LLMProvider(config)
    
    response = await llm.complete([
        {"role": "user", "content": "Hello"}
    ])
    
    assert isinstance(response, str)
    assert len(response) > 0

@pytest.mark.asyncio
async def test_llm_json_output(mock_litellm):
    """Le LLM doit retourner du JSON valide"""
    config = LLMProviderConfig(provider="openai", model="gpt-4o-mini", api_key="test")
    llm = LLMProvider(config)
    
    schema = {"type": "object", "properties": {"name": {"type": "string"}}}
    result = await llm.complete_json(
        [{"role": "user", "content": "Return a JSON with a name field"}],
        schema
    )
    
    assert isinstance(result, dict)
    assert "name" in result
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires LLM ex√©cut√©s : OK

---

### 5.2 Query Analyzer Agent

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **5.2.1** Impl√©menter l'agent Query Analyzer (`ragkit/agents/query_analyzer.py`)
  ```python
  class QueryAnalyzerAgent:
      """Agent qui analyse les requ√™tes utilisateur"""
      
      def __init__(self, config: QueryAnalyzerConfig, llm: LLMProvider):
          self.config = config
          self.llm = llm
          self.system_prompt = config.system_prompt
          self.output_schema = config.output_schema
      
      async def analyze(self, query: str, history: list[dict] | None = None) -> QueryAnalysis:
          """Analyse la requ√™te et retourne la d√©cision"""
          
          # Mode bypass : toujours faire du RAG
          if self.config.behavior.always_retrieve:
              return QueryAnalysis(
                  intent="question",
                  needs_retrieval=True,
                  rewritten_query=query,
                  reasoning="Always retrieve mode enabled"
              )
          
          # Construire le prompt
          messages = [
              {"role": "system", "content": self.system_prompt},
              {"role": "user", "content": f"Analyze this query: {query}"}
          ]
          
          # Appel LLM avec output JSON
          result = await self.llm.complete_json(messages, self.output_schema)
          
          return QueryAnalysis(**result)
  ```

- [x] **5.2.2** Impl√©menter la reformulation de requ√™te
  - Si `query_rewriting.enabled`, g√©n√©rer des variantes
  - Retourner la meilleure reformulation pour le retrieval

#### Test de Validation 5.2

```python
@pytest.mark.asyncio
async def test_query_analyzer_greeting():
    """Les salutations ne doivent pas d√©clencher le RAG"""
    agent = QueryAnalyzerAgent(default_config, mock_llm)
    
    result = await agent.analyze("Bonjour, comment √ßa va ?")
    
    assert result.intent in ["greeting", "chitchat"]
    assert result.needs_retrieval == False

@pytest.mark.asyncio
async def test_query_analyzer_question():
    """Les questions doivent d√©clencher le RAG"""
    agent = QueryAnalyzerAgent(default_config, mock_llm)
    
    result = await agent.analyze("Quelle est la proc√©dure de remboursement ?")
    
    assert result.intent == "question"
    assert result.needs_retrieval == True
    assert result.rewritten_query is not None

@pytest.mark.asyncio
async def test_query_analyzer_always_retrieve_mode():
    """Le mode always_retrieve doit court-circuiter l'analyse"""
    config = QueryAnalyzerConfig(behavior=BehaviorConfig(always_retrieve=True))
    agent = QueryAnalyzerAgent(config, mock_llm)
    
    result = await agent.analyze("Bonjour")
    
    # M√™me pour une salutation, needs_retrieval = True
    assert result.needs_retrieval == True
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires agents ex√©cut√©s : OK

---

### 5.3 Response Generator Agent

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **5.3.1** Impl√©menter l'agent Response Generator (`ragkit/agents/response_generator.py`)
  ```python
  class ResponseGeneratorAgent:
      """Agent qui g√©n√®re la r√©ponse finale"""
      
      def __init__(self, config: ResponseGeneratorConfig, llm: LLMProvider):
          self.config = config
          self.llm = llm
      
      async def generate(
          self,
          query: str,
          context: list[RetrievalResult] | None,
          analysis: QueryAnalysis,
          history: list[dict] | None = None
      ) -> GeneratedResponse:
          """G√©n√®re la r√©ponse selon le contexte"""
          
          # Choisir le prompt selon le type
          if not analysis.needs_retrieval:
              prompt = self._build_no_retrieval_prompt(query, analysis)
          elif analysis.intent == "out_of_scope":
              prompt = self._build_out_of_scope_prompt(query)
          else:
              prompt = self._build_rag_prompt(query, context)
          
          # Appel LLM
          response = await self.llm.complete(prompt)
          
          # Extraire les sources cit√©es
          sources = self._extract_sources(response, context)
          
          return GeneratedResponse(
              content=response,
              sources=sources,
              metadata={"intent": analysis.intent}
          )
      
      def _build_rag_prompt(self, query: str, context: list[RetrievalResult]) -> list[dict]:
          """Construit le prompt avec contexte RAG"""
          formatted_context = self._format_context(context)
          system = self.config.system_prompt.format(context=formatted_context)
          return [
              {"role": "system", "content": system},
              {"role": "user", "content": query}
          ]
  ```

- [x] **5.3.2** Impl√©menter le formatage du contexte
  - Inclure les m√©tadonn√©es (source, date)
  - Num√©roter les sources pour citation

- [x] **5.3.3** Impl√©menter l'extraction des sources cit√©es

#### Test de Validation 5.3

```python
@pytest.mark.asyncio
async def test_response_with_context():
    """La r√©ponse doit utiliser le contexte fourni"""
    agent = ResponseGeneratorAgent(default_config, mock_llm)
    
    context = [
        RetrievalResult(
            chunk=Chunk(id="1", content="Paris is the capital of France", metadata={"source": "geo.pdf"}),
            score=0.95
        )
    ]
    analysis = QueryAnalysis(intent="question", needs_retrieval=True)
    
    result = await agent.generate("What is the capital of France?", context, analysis)
    
    assert "Paris" in result.content
    assert len(result.sources) > 0

@pytest.mark.asyncio
async def test_response_cites_sources():
    """La r√©ponse doit citer les sources"""
    config = ResponseGeneratorConfig(behavior=BehaviorConfig(cite_sources=True))
    agent = ResponseGeneratorAgent(config, mock_llm)
    
    # ... setup ...
    result = await agent.generate(query, context, analysis)
    
    # V√©rifier que le format de citation est pr√©sent
    assert "[Source:" in result.content or len(result.sources) > 0

@pytest.mark.asyncio
async def test_response_without_retrieval():
    """Les r√©ponses sans RAG doivent √™tre g√©r√©es"""
    agent = ResponseGeneratorAgent(default_config, mock_llm)
    
    analysis = QueryAnalysis(intent="greeting", needs_retrieval=False)
    result = await agent.generate("Bonjour!", None, analysis)
    
    assert result.content is not None
    assert result.sources == []
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires agents ex√©cut√©s : OK

---

### 5.4 Agent Orchestrator

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **5.4.1** Cr√©er l'orchestrateur principal (`ragkit/agents/orchestrator.py`)
  ```python
  class AgentOrchestrator:
      """Orchestre le flux entre les agents"""
      
      def __init__(
          self,
          config: AgentsConfig,
          retrieval_engine: RetrievalEngine,
          llm_router: LLMRouter
      ):
          self.query_analyzer = QueryAnalyzerAgent(
              config.query_analyzer,
              llm_router.get(config.query_analyzer.llm)
          )
          self.response_generator = ResponseGeneratorAgent(
              config.response_generator,
              llm_router.get(config.response_generator.llm)
          )
          self.retrieval = retrieval_engine
      
      async def process(self, query: str, history: list[dict] | None = None) -> RAGResponse:
          """Traite une requ√™te de bout en bout"""
          
          # 1. Analyse de la requ√™te
          analysis = await self.query_analyzer.analyze(query, history)
          
          # 2. Retrieval (si n√©cessaire)
          context = None
          if analysis.needs_retrieval:
              search_query = analysis.rewritten_query or query
              context = await self.retrieval.retrieve(search_query)
          
          # 3. G√©n√©ration de la r√©ponse
          response = await self.response_generator.generate(
              query, context, analysis, history
          )
          
          return RAGResponse(
              query=query,
              analysis=analysis,
              context=context,
              response=response
          )
  ```

#### Test de Validation 5.4

```python
@pytest.mark.asyncio
async def test_full_orchestration():
    """L'orchestrateur doit ex√©cuter le flux complet"""
    orchestrator = AgentOrchestrator(config, retrieval_engine, llm_router)
    
    result = await orchestrator.process("What is machine learning?")
    
    assert result.analysis.needs_retrieval == True
    assert result.context is not None
    assert len(result.context) > 0
    assert result.response.content is not None

@pytest.mark.asyncio
async def test_orchestration_without_retrieval():
    """L'orchestrateur doit g√©rer les cas sans RAG"""
    orchestrator = AgentOrchestrator(config, retrieval_engine, llm_router)
    
    result = await orchestrator.process("Hello!")
    
    assert result.analysis.needs_retrieval == False
    assert result.context is None
    assert result.response.content is not None
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests unitaires orchestrateur ex√©cut√©s : OK

---

## Phase 6 : Interfaces

**Dur√©e estim√©e** : 5 jours  
**Statut** : üü¢ Termin√©

### 6.1 CLI

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **6.1.1** Cr√©er la structure CLI avec Typer (`ragkit/cli/main.py`)
  ```python
  import typer
  
  app = typer.Typer(name="ragkit", help="RAGKIT - Configuration-First RAG Framework")
  
  @app.command()
  def init(
      name: str = typer.Argument(..., help="Project name"),
      template: str = typer.Option("minimal", help="Template to use")
  ):
      """Initialize a new RAGKIT project"""
      
  @app.command()
  def ingest(
      config: Path = typer.Option("ragkit.yaml", help="Config file path")
  ):
      """Ingest documents into the vector store"""
      
  @app.command()
  def serve(
      config: Path = typer.Option("ragkit.yaml"),
      api_only: bool = typer.Option(False),
      chatbot_only: bool = typer.Option(False)
  ):
      """Start the RAGKIT server"""
      
  @app.command()
  def query(
      question: str = typer.Argument(...),
      config: Path = typer.Option("ragkit.yaml")
  ):
      """Query the RAG system from command line"""
  ```

- [x] **6.1.2** Impl√©menter `ragkit init`
- [x] **6.1.3** Impl√©menter `ragkit ingest`
- [x] **6.1.4** Impl√©menter `ragkit serve`
- [x] **6.1.5** Impl√©menter `ragkit query`
- [x] **6.1.6** Impl√©menter `ragkit validate` (validation de config)

#### Test de Validation 6.1

```bash
# Test manuel CLI
ragkit init test-project --template minimal
cd test-project
ragkit validate
ragkit ingest
ragkit query "Test question"
ragkit serve --api-only &
curl http://localhost:8000/health
```

**R√©sultat** : ‚¨ú Pass / ‚¨ú Fail  
**Notes** : Tests manuels non ex√©cut√©s

---

### 6.2 REST API

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **6.2.1** Cr√©er l'application FastAPI (`ragkit/api/app.py`)
  ```python
  from fastapi import FastAPI
  
  def create_app(config: RAGKitConfig) -> FastAPI:
      app = FastAPI(
          title="RAGKIT API",
          version="1.0.0",
          docs_url="/docs" if config.api.docs.enabled else None
      )
      
      # Injection des d√©pendances
      app.state.orchestrator = create_orchestrator(config)
      
      # Routes
      app.include_router(query_router)
      app.include_router(health_router)
      
      # Middleware
      if config.api.cors.enabled:
          app.add_middleware(CORSMiddleware, ...)
      
      return app
  ```

- [x] **6.2.2** Impl√©menter l'endpoint `/api/v1/query` (`ragkit/api/routes/query.py`)
  ```python
  @router.post("/query")
  async def query(
      request: QueryRequest,
      orchestrator: AgentOrchestrator = Depends(get_orchestrator)
  ) -> QueryResponse:
      result = await orchestrator.process(request.query, request.history)
      return QueryResponse(
          answer=result.response.content,
          sources=result.response.sources,
          metadata=result.response.metadata
      )
  ```

- [x] **6.2.3** Impl√©menter l'endpoint `/health`
- [x] **6.2.4** Ajouter le streaming avec SSE pour les r√©ponses longues
  - [x] Exposer un flag de configuration utilisateur (API + chatbot)

#### Test de Validation 6.2

```python
# tests/integration/test_api.py

def test_query_endpoint(client, populated_store):
    """L'endpoint query doit fonctionner"""
    response = client.post("/api/v1/query", json={
        "query": "What is machine learning?"
    })
    
    assert response.status_code == 200
    data = response.json()
    assert "answer" in data
    assert "sources" in data

def test_health_endpoint(client):
    """L'endpoint health doit retourner OK"""
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json()["status"] == "ok"
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests d'int√©gration API ex√©cut√©s (query/health) : OK

---

### 6.3 Chatbot Gradio

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **6.3.1** Cr√©er l'interface Gradio (`ragkit/chatbot/gradio_ui.py`)
  ```python
  import gradio as gr
  
  def create_chatbot(config: ChatbotConfig, orchestrator: AgentOrchestrator) -> gr.Blocks:
      
      async def respond(message: str, history: list):
          result = await orchestrator.process(message, history)
          
          response = result.response.content
          
          # Ajouter les sources si configur√©
          if config.features.show_sources and result.response.sources:
              response += "\n\n**Sources:**\n"
              for source in result.response.sources:
                  response += f"- {source}\n"
          
          return response
      
      with gr.Blocks(theme=config.ui.theme, title=config.ui.title) as demo:
          gr.Markdown(f"# {config.ui.title}")
          gr.Markdown(config.ui.description)
          
          chatbot = gr.ChatInterface(
              fn=respond,
              examples=config.ui.examples,
              textbox=gr.Textbox(placeholder=config.ui.placeholder)
          )
      
      return demo
  ```

- [x] **6.3.2** Ajouter l'affichage des sources
- [x] **6.3.3** Ajouter l'affichage de la latence
- [x] **6.3.4** G√©rer l'historique de conversation

#### Test de Validation 6.3

```python
def test_chatbot_creation():
    """Le chatbot doit se cr√©er sans erreur"""
    config = ChatbotConfig(enabled=True, type="gradio")
    orchestrator = MockOrchestrator()
    
    demo = create_chatbot(config, orchestrator)
    
    assert demo is not None
    # Gradio app doit avoir les composants attendus

# Test manuel
# ragkit serve --chatbot-only
# Ouvrir http://localhost:8080
# Poser des questions et v√©rifier les r√©ponses
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Test unitaire chatbot ajout√© (skipped si Gradio absent)

---

## Phase 7 : Integration & Polish

**Dur√©e estim√©e** : 5 jours  
**Statut** : üü° En cours

### 7.1 Tests End-to-End

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **7.1.1** Cr√©er les fixtures E2E (`tests/e2e/conftest.py`)
- [x] **7.1.2** √âcrire le test du pipeline complet
  ```python
  @pytest.mark.e2e
  async def test_full_pipeline(tmp_path):
      """Test E2E : init ‚Üí ingest ‚Üí query ‚Üí response"""
      
      # 1. Cr√©er un projet
      project_dir = tmp_path / "test_project"
      subprocess.run(["ragkit", "init", str(project_dir), "--template", "minimal"])
      
      # 2. Ajouter des documents
      docs_dir = project_dir / "data" / "documents"
      docs_dir.mkdir(parents=True)
      (docs_dir / "test.md").write_text("# Test\nThis is about machine learning.")
      
      # 3. Configurer
      config_path = project_dir / "ragkit.yaml"
      # ... modifier la config pour utiliser des mocks ou des services locaux
      
      # 4. Ing√©rer
      subprocess.run(["ragkit", "ingest", "-c", str(config_path)])
      
      # 5. Query
      result = subprocess.run(
          ["ragkit", "query", "What is this about?", "-c", str(config_path)],
          capture_output=True,
          text=True
      )
      
      assert "machine learning" in result.stdout.lower()
  ```

- [x] **7.1.3** Tests de charge basiques
- [x] **7.1.4** Tests de r√©gression sur les configurations

#### Test de Validation 7.1

```bash
pytest tests/e2e/ -v --tb=short
```

**R√©sultat** : ‚úÖ Pass / ‚¨ú Fail  
**Notes** : Tests E2E ex√©cut√©s (pipeline, charge basique, regression configs).

---

### 7.2 Documentation

**Statut** : üü¢ Termin√©  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **7.2.1** √âcrire `README.md` complet
  - Installation
  - Quickstart (5 min)
  - Configuration de base
  - Liens vers docs d√©taill√©es

- [x] **7.2.2** √âcrire `docs/getting-started.md`
- [x] **7.2.3** √âcrire `docs/configuration.md` (r√©f√©rence compl√®te)
- [x] **7.2.4** √âcrire `docs/api-reference.md`
- [x] **7.2.5** Cr√©er des exemples dans `examples/`

---

### 7.3 Packaging & Release

**Statut** : üü° En cours  
**Assign√© √†** : _√Ä compl√©ter_

#### T√¢ches

- [x] **7.3.1** Finaliser `pyproject.toml`
- [x] **7.3.2** Cr√©er le `Dockerfile`
- [x] **7.3.3** Cr√©er le `docker-compose.yaml`
- [x] **7.3.4** Configurer CI/CD (GitHub Actions)
  - Tests automatiques
  - Lint/format check
  - Build du package
  - Publication sur PyPI (optionnel)

- [ ] **7.3.5** Cr√©er la release v1.0.0
  - Tag Git
  - Changelog
  - Assets (wheel, source)

---

## üìä Suivi Global

### M√©triques de Progression

| Phase | T√¢ches Total | Compl√©t√©es | % |
|-------|-------------|------------|---|
| Phase 1: Foundation | 15 | 15 | 100% |
| Phase 2: Ingestion | 18 | 18 | 100% |
| Phase 3: Embedding & Storage | 12 | 12 | 100% |
| Phase 4: Retrieval | 15 | 15 | 100% |
| Phase 5: LLM & Agents | 14 | 14 | 100% |
| Phase 6: Interfaces | 12 | 12 | 100% |
| Phase 7: Integration | 10 | 9 | 90% |
| **TOTAL** | **96** | **95** | **99%** |

### Blockers Actuels

| ID | Description | Impact | Responsable | Date identifi√©e |
|----|-------------|--------|-------------|-----------------|
| - | - | - | - | - |

### D√©cisions Techniques Prises

| Date | D√©cision | Justification | Alternatives consid√©r√©es |
|------|----------|---------------|-------------------------|
| - | - | - | - |

---

## üìù Notes de Mise √† Jour

_Ajouter ici les notes au fur et √† mesure de l'avancement_

```
[30/01/2026] - Codex
- Phase 1 termin√©e : scaffold projet, config system, utilitaires, tests unitaires initiaux.
- Templates minimal/hybrid/full ajout√©s.
- Mise √† jour des statuts et m√©triques.
- Tests unitaires Phase 1 ex√©cut√©s : 7 tests OK (pytest). Avertissement pytest-asyncio sur `asyncio_default_fixture_loop_scope`.
- Phase 2 termin√©e : sources locales, parsers, chunkers, pipeline ingestion (retry/logging/incr√©mental).
- Tests unitaires Phase 2 ex√©cut√©s (sources/parsers/chunkers) : 7 tests OK. Avertissement pytest-asyncio corrig√© (scope configur√©).
- Fix pytest-asyncio: `asyncio_default_fixture_loop_scope=function` ajout√© √† `pytest.ini` et tests relanc√©s (OK).
- Phase 3 termin√©e : embedders (LiteLLM), cache, vector stores Qdrant/Chroma + factory.
- Tests Phase 3 ex√©cut√©s : cache OK, vector stores OK (warnings de d√©pr√©ciation c√¥t√© qdrant/chroma).
- Phase 4 termin√©e : retrievers s√©mantique/lexical, fusion, reranker, moteur de retrieval.
- Tests Phase 4 ex√©cut√©s : `tests/unit/test_retrieval.py` OK.
- Phase 5 termin√©e : LLM LiteLLM wrapper/router, agents (query analyzer, response generator), orchestrateur.
- Tests Phase 5 ex√©cut√©s : `tests/unit/test_llm.py` et `tests/unit/test_agents.py` OK.
- Phase 6 termin√©e : CLI, API, chatbot Gradio, streaming configurable (API SSE + chatbot).
- Tests Phase 6 ex√©cut√©s : `tests/integration/test_api.py` OK, chatbot skipp√© si Gradio absent.
- Phase 7 avanc√©e : tests E2E, docs, packaging (Dockerfile, docker-compose, CI). Release v1.0.0 reste √† faire.
- Tests E2E ex√©cut√©s : `pytest tests/e2e` OK.

[DATE] - [AUTEUR]
- Note 1
- Note 2
```
