Il y des am√©liorations √† pr√©voir pour satisfaire les exigences attendues de ragkit par exemple ,
il faut pr√©voir une structure de m√©tadonn√©es par d√©faut mais bien large pour permettre d'abord une base propre pour la suite. 
L'application pr√©voit une structure  de m√©tadonn√©es par d√©faut par document (d√©tectable automatiquement par l'application et modifiable ensuite par l'utilisateur ) 
Exemple de structure des m√©tadonn√©es √† compl√©ter : Tenant>Domaine> sous domaines> Titre> auteur>source>date>tags etc... 
Donc pour am√©liorer l'application on pr√©voit    
le plan d'am√©lioration  par grand domaine de param√©trages 
Comme ca on am√©liore chaque domaine et valide le domaine avant de passer au domaine suivant. Domaines dans l'ordre. 
1- INGESTION & PREPROCESSING : 
Document Parsing
Text Preprocessing
2- CHUNKING : 
Strat√©gie de D√©coupage
Param√®tres de Taille
S√©parateurs et D√©limiteurs
Chunking Avanc√©
Metadata Enrichment
3- EMBEDDING
Choix du Mod√®le
Dimensions
Normalisation
Batching
Gestion des Tokens
4- BASE DE DONN√âES VECTORIELLE
Choix de la DB
M√©trique de Distance
Type d'Index
Param√®tres HNSW 
Param√®tres IVF 
Quantization
Sharding & R√©plication
Filtrage
5- RECHERCHE S√âMANTIQUE
Query Processing
Retrieval Parameters
Diversification
Filtres Metadata
6- RECHERCHE LEXICALE
Tokenization
Stemming & Lemmatization
Param√®tres BM25
N-grams
7- RECHERCHE HYBRIDE (Fusion)
Pond√©ration
M√©thode de Fusion
Normalisation des Scores
Strat√©gies Avanc√©es
8- RERANKING
Mod√®le de Reranking
Param√®tres de Reranking
Output
Strat√©gies Multi-√©tapes
9- LLM / G√âN√âRATION
Choix du Mod√®le
Param√®tres de G√©n√©ration
Prompt Engineering
Context Management
Citation & Attribution
Fallback & Guardrails
10- CACHE & PERFORMANCE
cache de Requ√™tes
Cache d'Embeddings
Batching & Async
Warmup
11- MONITORING & EVALUATION
M√©triques de Retrieval
M√©triques de G√©n√©ration
Performance
Logging & Observability
12- S√âCURIT√â & COMPLIANCE
Authentification & Autorisation
Privacy
Content Moderation
13- MISE √Ä JOUR & MAINTENANCE
Indexation Incr√©mentale
versioning
Refresh

Chaque domaine doit √™tre une Etape d'am√©lriation , et une Etape doit contenir plusieurs phases et √† la fin on peut installer l'application la tester et valider.
Pour l'interface UI chaque domaine de param√®trage doit apparaitre explicitement dans les param√®tres avec des valeurs de param√®tres par d√©faut ou non 
Si tu valide cette nouvelle fa√ßon incr√©mentale d'am√©liorer  RAGkit, cr√©e un dossier improve_ragkit/ dans lequel tu √©cris un  roadmap complet + le plan d'impl√©mentaion d'am√©lioration pour chaque √©tape. 
Un doc par √©tape 
L'id√©e c'est de suivre le roadmap √©tape par √©tape et de valider l'application par domaine de param√®trage. Exemple quand on finit d'impl√©menter l'am√©lioration de l'√©tape 1, on construit 
l'application en local dans C:\Users\henri\Projets\ragkit\.build j'installe et teste et valide avant de passer √† l'√©tape suivante 


Principe d'am√©lioration  : "√âtrangler et enrichir" (Strangler Fig Pattern) par rapport aux param√®tres de chaque √©tape dans parametres_rag_exhaustif.md
On garde le code existant comme base fonctionnelle, et pour chaque √©tape du roadmap on fait :

Auditer ‚Äî Lister ce qui existe d√©j√† dans le code actuel pour ce domaine (ex : les parsers existent, le LexicalRetriever existe)
Compl√©ter ‚Äî Ajouter ce qui manque par rapport au plan (ex : la structure de m√©tadonn√©es enrichie, les param√®tres BM25 non branch√©s)
Brancher ‚Äî Connecter les morceaux qui existent mais ne sont pas reli√©s (ex : l'index lexical jamais aliment√©)
Tester & valider ‚Äî √âcrire les tests de validation de l'√©tape, s'assurer que tout passe

Pour les m√©tadonn√©es enrichies je propose : DocumentMetadata
Hi√©rarchie organisationnelle

tenant ‚Äî Organisation / client
domain ‚Äî Domaine m√©tier
subdomain ‚Äî Sous-domaine

Identification document

document_id ‚Äî ID unique g√©n√©r√©
title ‚Äî Extrait du H1 ou nom de fichier
author ‚Äî Extrait des m√©tadonn√©es PDF/DOCX
source ‚Äî Nom du fichier
source_path ‚Äî Chemin relatif
source_type ‚Äî pdf, docx, md, txt, html, csv
source_url ‚Äî URL d'origine si applicable
mime_type ‚Äî MIME type d√©tect√©

Temporalit√©

created_at ‚Äî Date de cr√©ation du document
modified_at ‚Äî Derni√®re modification
ingested_at ‚Äî Timestamp d'ingestion
version ‚Äî Version du document

Contenu (auto-d√©tect√©)

language ‚Äî Langue ISO 639-1
page_count
word_count
char_count
has_tables
has_images
has_code
encoding

Classification (modifiable par l'utilisateur)

tags ‚Äî Liste libre
category ‚Äî Cat√©gorie pr√©d√©finie
confidentiality ‚Äî public / internal / confidential / secret
status ‚Äî draft / review / published / archived

Parsing (syst√®me)

parser_engine ‚Äî Moteur utilis√©
ocr_applied ‚Äî OCR d√©clench√© ou non
parsing_quality ‚Äî Score 0-1
parsing_warnings ‚Äî Avertissements

Extensible

custom ‚Äî Dictionnaire libre cl√©/valeur


ChunkMetadata (h√©rit√© + enrichi)
H√©rit√© du document : document_id, tenant, domain, title, source, language, tags
Sp√©cifique au chunk

chunk_id
chunk_index ‚Äî Position dans le document
total_chunks
chunk_strategy ‚Äî fixed / semantic / recursive
chunk_size_tokens
chunk_size_chars

Contexte structurel

page_number
section_title ‚Äî Titre de section parent
heading_path ‚Äî Fil d'Ariane des headings
paragraph_index

Relations

previous_chunk_id
next_chunk_id
parent_chunk_id ‚Äî Pour le parent-child chunking

Actuellement j'ai not√© les am√©liorations suivantes √† apporter :
Am√©liorations √† apporter √† la version actuelle
INGESTION & PREPROCESSING

Ajouter la structure de m√©tadonn√©es enrichie (tenant/domain/subdomain/tags/etc.)
Auto-d√©tection des m√©tadonn√©es document (title, author, language, page_count)
Exposer OCR dans l'UI (actuellement backend only)
Ajouter le preprocessing texte (normalisation unicode, suppression URLs, whitespace)
Ajouter la d√©duplication √† l'ingestion (exact + fuzzy)
Exposer la d√©tection de langue dans l'UI

CHUNKING

Ajouter les strat√©gies manquantes (sentence_based, paragraph_based, recursive)
Ajouter min_chunk_size / max_chunk_size
Corriger le chunking s√©mantique (m√©thode sync inexistante)
Ajouter le parent-child chunking
Enrichir les ChunkMetadata (page_number, section_title, heading_path, relations prev/next)
Inclure le titre du document dans chaque chunk

EMBEDDING

Ajouter multilingual-e5-large dans les mod√®les ONNX support√©s
Auto-t√©l√©chargement du mod√®le embedding au premier lancement
Exposer embedding_batch_size et normalize_embeddings dans l'UI

BASE VECTORIELLE

Exposer distance_metric dans l'UI
Exposer les param√®tres HNSW (ef_construction, ef_search, M) dans l'UI

RECHERCHE S√âMANTIQUE

Exposer MMR (enabled, lambda, diversity_threshold) dans l'UI
Ajouter query_expansion (synonymes, reformulation)

RECHERCHE LEXICALE

Brancher l'index lexical dans le pipeline d'ingestion (bug critique)
Persister l'index BM25 sur disque (perdu √† chaque red√©marrage)
Inclure les m√©tadonn√©es dans l'index BM25 (title, source en plus du content)
Exposer bm25_delta, tokenizer_type, lemmatization dans l'UI
Ajouter le support n-grams
Ajouter custom_stopwords

RECHERCHE HYBRIDE

Exposer normalization_method (min-max, z-score) dans l'UI
Ajouter dynamic_alpha (ajustement auto selon le type de requ√™te)

RERANKING

Ajouter un reranker local (cross-encoder) en plus de Cohere
Ajouter le reranking multi-√©tapes

LLM / G√âN√âRATION

Exposer frequency_penalty et presence_penalty dans l'UI
Ajouter citation_format configurable (inline, footnote, [1])
Ajouter confidence_threshold (r√©pondre "je ne sais pas" si score trop bas)

CACHE & PERFORMANCE

Ajouter un cache de requ√™tes (exact + s√©mantique)
Ajouter le warmup au d√©marrage

MONITORING

Ajouter les m√©triques retrieval (precision@k, recall@k, MRR)
Ajouter le feedback utilisateur (üëçüëé)

TRANSVERSE

Corriger les vector stores sync dans du code async (ChromaDB, Qdrant)
Corriger l'import cass√© dans desktop/kb_manager.py
Impl√©menter le pipeline RAG dans le desktop (actuellement placeholder)